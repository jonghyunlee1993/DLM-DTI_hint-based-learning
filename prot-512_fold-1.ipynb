{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b8b3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjonghyunlee1993\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/Workspace/DLM_DTI/wandb/run-20230331_224403-36vjjqju</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jonghyunlee1993/DLM_DTI_hint_based_learning_new/runs/36vjjqju' target=\"_blank\">prot-512_fold-1</a></strong> to <a href='https://wandb.ai/jonghyunlee1993/DLM_DTI_hint_based_learning_new' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jonghyunlee1993/DLM_DTI_hint_based_learning_new' target=\"_blank\">https://wandb.ai/jonghyunlee1993/DLM_DTI_hint_based_learning_new</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jonghyunlee1993/DLM_DTI_hint_based_learning_new/runs/36vjjqju' target=\"_blank\">https://wandb.ai/jonghyunlee1993/DLM_DTI_hint_based_learning_new/runs/36vjjqju</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device_no = 0\n",
    "max_length = 512\n",
    "fold_num = 1\n",
    "PROJECT_NAME = f\"prot-{max_length}_fold-{fold_num}\"\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "import torchmetrics\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "wandb_logger = WandbLogger(name=f'{PROJECT_NAME}',\n",
    "                           project='DLM_DTI_hint_based_learning_new')\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizer, RobertaTokenizer\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "train_df = pd.read_csv(\"data/train_dataset.csv\")\n",
    "valid_df = pd.read_csv(\"data/valid_dataset.csv\")\n",
    "test_df = pd.read_csv(\"data/test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20860e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"prot_feat/{max_length}_cls.pkl\", \"rb\") as f:\n",
    "    prot_feat_teacher = pickle.load(f)\n",
    "\n",
    "class DTIDataset(Dataset):\n",
    "    def __init__(self, data, prot_feat_teacher, \n",
    "                 mol_tokenizer, prot_tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.prot_feat_teacher = prot_feat_teacher\n",
    "        self.max_length = max_length\n",
    "        self.mol_tokenizer = mol_tokenizer\n",
    "        self.prot_tokenizer = prot_tokenizer\n",
    "        \n",
    "    def get_mol_feat(self, smiles):\n",
    "        return self.mol_tokenizer(smiles, max_length=512, truncation=True)\n",
    "    \n",
    "    def get_prot_feat_teacher(self, fasta):\n",
    "        return self.prot_tokenizer(\" \".join(fasta), max_length=self.max_length, truncation=True)\n",
    "    \n",
    "    def get_prot_feat_student(self, fasta):\n",
    "        return self.prot_feat_teacher[fasta[:20]]\n",
    "    \n",
    "    def __len__(self):    \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        smiles = self.data.loc[index, \"SMILES\"]\n",
    "        mol_feat = self.get_mol_feat(smiles)\n",
    "        \n",
    "        fasta = self.data.loc[index, \"Target Sequence\"]\n",
    "        prot_feat_student = self.get_prot_feat_teacher(fasta)\n",
    "        prot_feat_teacher = self.get_prot_feat_student(fasta)\n",
    "        \n",
    "        y = self.data.loc[index, \"Label\"]\n",
    "        source = self.data.loc[index, \"Source\"]\n",
    "        if source == \"DAVIS\":\n",
    "            source = 1\n",
    "        elif source == \"BindingDB\":\n",
    "            source = 2\n",
    "        elif source == \"BIOSNAP\":\n",
    "            source = 3\n",
    "                \n",
    "        return mol_feat, prot_feat_student, prot_feat_teacher, y, source\n",
    "\n",
    "    \n",
    "def collate_batch(batch):\n",
    "    mol_features, prot_feat_student, prot_feat_teacher, y, source = [], [], [], [], []\n",
    "    \n",
    "    for (mol_seq, prot_seq_student, prot_seq_teacher, y_, source_) in batch:\n",
    "        mol_features.append(mol_seq)\n",
    "        prot_feat_student.append(prot_seq_student)\n",
    "        prot_feat_teacher.append(prot_seq_teacher.detach().cpu().numpy().tolist())\n",
    "        y.append(y_)\n",
    "        source.append(source_)\n",
    "        \n",
    "    mol_features = mol_tokenizer.pad(mol_features, return_tensors=\"pt\")\n",
    "    prot_feat_student = prot_tokenizer.pad(prot_feat_student, return_tensors=\"pt\")\n",
    "    prot_feat_teacher = torch.tensor(prot_feat_teacher).float()\n",
    "    y = torch.tensor(y).float()\n",
    "    source = torch.tensor(source)\n",
    "    \n",
    "    return mol_features, prot_feat_student, prot_feat_teacher, y, source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2e86661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "mol_tokenizer = RobertaTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "mol_encoder = AutoModel.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "\n",
    "prot_tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "# prot_encoder = AutoModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "\n",
    "for param in mol_encoder.embeddings.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for layer in mol_encoder.encoder.layer[:6]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "config = BertConfig(\n",
    "    vocab_size=prot_tokenizer.vocab_size,\n",
    "    hidden_size=512,\n",
    "    num_hidden_layers=4,\n",
    "    num_attention_heads=4,\n",
    "    intermediate_size=2048,\n",
    "    hidden_act=\"gelu\",\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    max_position_embeddings=max_length + 2,\n",
    "    type_vocab_size=1,\n",
    "    pad_token_id=0,\n",
    "    position_embedding_type=\"absolute\"\n",
    ")\n",
    "\n",
    "prot_encoder = BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc8801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DTIDataset(train_df, prot_feat_teacher, \n",
    "                           mol_tokenizer, prot_tokenizer, max_length)\n",
    "valid_dataset = DTIDataset(valid_df, prot_feat_teacher, \n",
    "                           mol_tokenizer, prot_tokenizer, max_length)\n",
    "test_dataset = DTIDataset(test_df, prot_feat_teacher, \n",
    "                          mol_tokenizer, prot_tokenizer, max_length)\n",
    "\n",
    "counts = np.bincount(train_df[\"Label\"])\n",
    "labels_weights = 1. / counts\n",
    "weights = labels_weights[train_df[\"Label\"]]\n",
    "sampler = WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, num_workers=32, \n",
    "                              pin_memory=True, prefetch_factor=10, drop_last=True, \n",
    "                              sampler=sampler, collate_fn=collate_batch)\n",
    "\n",
    "valid_dataloader = DataLoader(train_dataset, batch_size=128, num_workers=32, \n",
    "                              pin_memory=True, prefetch_factor=10, \n",
    "                              drop_last=False, collate_fn=collate_batch)\n",
    "\n",
    "test_dataloader = DataLoader(train_dataset, batch_size=128, num_workers=32, \n",
    "                             pin_memory=True, prefetch_factor=10, \n",
    "                             drop_last=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dca0609",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTI(nn.Module):\n",
    "    def __init__(self, mol_encoder, prot_encoder, \n",
    "                 hidden_dim=512, mol_dim=128, prot_dim=1024):\n",
    "        super().__init__()\n",
    "        self.mol_encoder = mol_encoder\n",
    "        self.prot_encoder = prot_encoder\n",
    "        \n",
    "        self.lambda_ = torch.nn.Parameter(torch.rand(1).to(f\"cuda:{device_no}\"), requires_grad=True)\n",
    "                    \n",
    "        self.molecule_align = nn.Sequential(\n",
    "            nn.LayerNorm(mol_dim),\n",
    "            nn.Linear(mol_dim, hidden_dim, bias=False)\n",
    "        )\n",
    "        \n",
    "        self.protein_align_teacher = nn.Sequential(\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.Linear(1024, hidden_dim, bias=False)\n",
    "        )\n",
    "        \n",
    "        self.protein_align_student = nn.Sequential(\n",
    "            nn.LayerNorm(prot_dim),\n",
    "            nn.Linear(prot_dim, hidden_dim, bias=False)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim * 4)\n",
    "        self.fc2 = nn.Linear(hidden_dim * 4, hidden_dim * 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        \n",
    "        self.cls_out = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, SMILES, FASTA, prot_feat_teacher):\n",
    "        mol_feat = self.mol_encoder(**SMILES).last_hidden_state[:, 0]\n",
    "        prot_feat = self.prot_encoder(**FASTA).last_hidden_state[:, 0]\n",
    "        \n",
    "        mol_feat = self.molecule_align(mol_feat)\n",
    "        prot_feat = self.protein_align_student(prot_feat)\n",
    "        prot_feat_teacher = self.protein_align_teacher(prot_feat_teacher).squeeze(1)\n",
    "        \n",
    "        lambda_ = torch.sigmoid(self.lambda_)\n",
    "        merged_prot_feat = lambda_ * prot_feat + (1 - lambda_) * prot_feat_teacher\n",
    "    \n",
    "        x = torch.cat([mol_feat, merged_prot_feat], dim=1)\n",
    "\n",
    "        x = F.dropout(F.gelu(self.fc1(x)), 0.1)\n",
    "        x = F.dropout(F.gelu(self.fc2(x)), 0.1)\n",
    "        x = F.dropout(F.gelu(self.fc3(x)), 0.1)\n",
    "        \n",
    "        cls_out = self.cls_out(x).squeeze(-1)\n",
    "        \n",
    "        return cls_out, lambda_\n",
    "        \n",
    "model = DTI(mol_encoder, prot_encoder,\n",
    "            hidden_dim=512, mol_dim=768, prot_dim=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44753d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "class DTI_prediction(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    \n",
    "    def step(self, batch):\n",
    "        mol_feature, prot_feat_student, prot_feat_teacher, y, source = batch\n",
    "        prot_feat_teacher = prot_feat_teacher.detach()\n",
    "        pred, lambda_ = self.model(mol_feature, prot_feat_student, prot_feat_teacher)\n",
    "        \n",
    "        loss = F.binary_cross_entropy_with_logits(pred, y)\n",
    "        \n",
    "        pred = F.sigmoid(pred)\n",
    "        auroc = torchmetrics.functional.auroc(pred, y.long())\n",
    "        auprc = torchmetrics.functional.average_precision(pred, y.long())\n",
    "        \n",
    "        return pred, y, source, loss, lambda_\n",
    "        \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, _, _, loss, lambda_ = self.step(batch)\n",
    "        \n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_lambda_', lambda_, on_step=True, on_epoch=True, prog_bar=False)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        preds, y, _, loss, lambda_ = self.step(batch)\n",
    "        self.log('valid_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('valid_lambda_', lambda_, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return {'preds': preds, 'target': y}\n",
    "\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        preds = torch.cat([tmp['preds'] for tmp in outputs], 0).detach().cpu()\n",
    "        targets = torch.cat([tmp['target'] for tmp in outputs], 0).detach().cpu().long()\n",
    "\n",
    "        auroc = torchmetrics.functional.auroc(preds, targets.long())\n",
    "        auprc = torchmetrics.functional.average_precision(preds, targets.long())\n",
    "        self.log('valid_auroc', auroc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('valid_auprc', auprc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "#         conf_mat = torchmetrics.functional.confusion_matrix(preds, targets, num_classes=2)\n",
    "\n",
    "#         print(f'Epoch : {self.trainer.current_epoch}')\n",
    "#         print(conf_mat)\n",
    "    \n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        preds, y, _, loss, _ = self.step(batch)\n",
    "        self.logging([loss, auroc, auprc], mode='test')\n",
    "        \n",
    "        return {'preds': preds, 'target': y}\n",
    "    \n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        preds = torch.cat([tmp['preds'] for tmp in outputs], 0).detach().cpu()\n",
    "        targets = torch.cat([tmp['target'] for tmp in outputs], 0).detach().cpu().long()\n",
    "        \n",
    "        auroc = torchmetrics.functional.auroc(preds, targets.long())\n",
    "        auprc = torchmetrics.functional.average_precision(preds, targets.long())\n",
    "        self.log('test_auroc', auroc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('test_auprc', auprc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        conf_mat = torchmetrics.functional.confusion_matrix(preds, targets, num_classes=2)\n",
    "\n",
    "        print(conf_mat)\n",
    "    \n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        pred, y, source, _, _ = self.step(batch)\n",
    "        \n",
    "        return pred, y, source\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=5e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10*len(train_dataloader))\n",
    "        \n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "          \n",
    "    \n",
    "callbacks = [\n",
    "    ModelCheckpoint(monitor='valid_loss',\n",
    "                    save_top_k=1, dirpath=f'weights/{PROJECT_NAME}', \n",
    "                    filename='DTI-{epoch:03d}-{valid_loss:.4f}-{valid_auroc:.4f}-{valid_auprc:.4f}'),\n",
    "]\n",
    "\n",
    "predictor = DTI_prediction(model)\n",
    "trainer = pl.Trainer(max_epochs=30, gpus=[device_no], enable_progress_bar=True, \n",
    "                     callbacks=callbacks, precision=16, logger=wandb_logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7be3091",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | DTI  | 63.2 M\n",
      "-------------------------------\n",
      "19.6 M    Trainable params\n",
      "43.5 M    Non-trainable params\n",
      "63.2 M    Total params\n",
      "126.326   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4102a30215144cea6efd6c848100968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(predictor, train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49ec4f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac76cc0381f44ac9976eedddd31dd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 265it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictor = predictor.load_from_checkpoint(f\"weights/{PROJECT_NAME}/DTI-epoch=029-valid_loss=0.2288-valid_auroc=0.9699-valid_auprc=0.9696.ckpt\",\n",
    "                                          model=model)\n",
    "out = trainer.predict(predictor, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "594d6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "davis_pred, davis_target = [], []\n",
    "binding_pred, binding_target = [], []\n",
    "biosnap_pred, biosnap_target = [], []\n",
    "\n",
    "for batch in out:\n",
    "    for i in range(batch[0].shape[0]):\n",
    "        pred = batch[0][i].detach().numpy().tolist()\n",
    "        target = batch[1][i].detach().numpy().tolist()\n",
    "        source = batch[2][i].detach().numpy().tolist()\n",
    "\n",
    "        if source == 1:\n",
    "            davis_pred.append(pred)\n",
    "            davis_target.append(target)\n",
    "        elif source == 2:\n",
    "            binding_pred.append(pred)\n",
    "            binding_target.append(target)\n",
    "        elif source == 3:\n",
    "            biosnap_pred.append(pred)\n",
    "            biosnap_target.append(target)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "477cf8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAVIS\tAUROC:0.9582\tAUPRC:0.9578\tSen:0.9492\tSpec:0.7814\n",
      "Binding\tAUROC:0.9694\tAUPRC:0.9688\tSen:0.9318\tSpec:0.8688\n",
      "BIOSNAP\tAUROC:0.9714\tAUPRC:0.9714\tSen:0.9294\tSpec:0.8868\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix\n",
    "\n",
    "davis_pred_label = np.where(np.array(davis_pred) >= 0.5, 1, 0)\n",
    "binding_pred_label = np.where(np.array(binding_pred) >= 0.5, 1, 0)\n",
    "biosnap_pred_label = np.where(np.array(biosnap_pred) >= 0.5, 1, 0)\n",
    "\n",
    "def compute_sen_spec(y_test, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    sensitivity = (tp / (tp + fn)).round(4)\n",
    "    specificity = (tn / (tn + fp)).round(4)\n",
    "\n",
    "    return sensitivity, specificity\n",
    "\n",
    "davis_auroc = roc_auc_score(davis_target, davis_pred).round(4)\n",
    "davis_auprc = average_precision_score(davis_target, davis_pred).round(4)\n",
    "davis_sen, davis_spec = compute_sen_spec(davis_target, davis_pred_label)\n",
    "\n",
    "binding_auroc = roc_auc_score(binding_target, binding_pred).round(4)\n",
    "binding_auprc = average_precision_score(binding_target, binding_pred).round(4)\n",
    "binding_sen, binding_spec = compute_sen_spec(binding_target, binding_pred_label)\n",
    "\n",
    "biosnap_auroc = roc_auc_score(biosnap_target, biosnap_pred).round(4)\n",
    "biosnap_auprc = average_precision_score(biosnap_target, biosnap_pred).round(4)\n",
    "biosnap_sen, biosnap_spec = compute_sen_spec(biosnap_target, biosnap_pred_label)\n",
    "\n",
    "print(f\"DAVIS\\tAUROC:{davis_auroc}\\tAUPRC:{davis_auprc}\\tSen:{davis_sen}\\tSpec:{davis_spec}\")\n",
    "print(f\"Binding\\tAUROC:{binding_auroc}\\tAUPRC:{binding_auprc}\\tSen:{binding_sen}\\tSpec:{binding_spec}\")\n",
    "print(f\"BIOSNAP\\tAUROC:{biosnap_auroc}\\tAUPRC:{biosnap_auprc}\\tSen:{biosnap_sen}\\tSpec:{biosnap_spec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1879b40b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
