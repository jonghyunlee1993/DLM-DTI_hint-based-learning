dataset: merged

device: 0

prot_length: 
    teacher: 1024
    student: 1024


lambda:
    learnable: True
    fixed_value: -1


prot_encoder:
    hidden_size: 512
    num_hidden_layers: 4
    num_attention_heads: 4
    intermediate_size: 2048
    hidden_act: "gelu"


training_config:
    batch_size: 64
    num_workers: 32
    epochs: 30
    hidden_dim: 512

